{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train rt-detr to detect weeds in potato fields\n",
        "\n",
        "In this notebook we'll train a [rt-detr](https://docs.ultralytics.com/models/rtdetr/) model to detect weeds in a potato fields. \n",
        "The target weeds are:\n",
        "- kikuyo\n",
        "- lengua de vaca\n",
        "- diente de le√≥n\n",
        "\n",
        "These weeds are common in potatoes fields. The images was captured in 9-10 meters height with a drone. Then, the images was selected and cropped \n",
        "to 1920x1920 pixels. Finally, the images was labeled with Roboflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "## Install dependencies\n",
        "First of all, we'll check the GPU, and install the dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python --version\n",
        "!cat /etc/os-release"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q coco-eval pycocotools supervision ultralytics\n",
        "!pip install -q wandb ipywidgets --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize weights & biases\n",
        "We'll use weights & biases to log the training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "from kaggle_secrets import UserSecretsClient\n",
        "\n",
        "project_name = 'rt-detr-potatoes-final'\n",
        "name = 'train-default-config'\n",
        "user_secrets = UserSecretsClient()\n",
        "key = user_secrets.get_secret('wandb')\n",
        "\n",
        "\n",
        "wandb.login(key=key)\n",
        "wandb.init(project=project_name, name=name, job_type='training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create function to create data.yaml file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "base_config = {\n",
        "    'path': '/path/to/dataset',\n",
        "    'train': 'train/images',\n",
        "    'val': 'valid/images',\n",
        "    'test': 'test/images',\n",
        "    'names': {\n",
        "        0: 'class_a',\n",
        "        1: 'class_b',\n",
        "        2: 'class_c'\n",
        "    },\n",
        "}\n",
        "\n",
        "default_config = {\n",
        "    'imgsz': 640,\n",
        "    'epochs': 100,\n",
        "    'patience': 100,\n",
        "    'batch': 8,\n",
        "    'optimizer': 'auto',\n",
        "    'split': 'val',\n",
        "    'save_json': True,\n",
        "    'iou': 0.7,\n",
        "    'max_det': 300,\n",
        "    'lr0': 0.01,\n",
        "    'lrf': 0.01,\n",
        "    'momentum': 0.937,\n",
        "    'weight_decay': 0.0005,\n",
        "    'hsv_h': 0.015,\n",
        "    'hsv_s': 0.7,\n",
        "    'hsv_v': 0.4,\n",
        "    'degrees': 0.0,\n",
        "    'translate': 0.1,\n",
        "    'flipud': 0.0,\n",
        "    'fliplr': 0.5,\n",
        "    'mosaic': 1.0,\n",
        "    'erasing': 0.4,\n",
        "    'crop_fraction': 1.0,\n",
        "}\n",
        "\n",
        "\n",
        "def create_configuration_file(data: dict = None, filename: str = 'data.yaml', use_default_config: bool = False):\n",
        "    '''Create configuration file with default values\n",
        "\n",
        "    Args:\n",
        "    ----\n",
        "        data (dict): Data to write to configuration file\n",
        "        filename (str): Name of the configuration file\n",
        "        use_default_config (bool): Create configuration file with default values\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "        str: Name of the configuration file\n",
        "    '''\n",
        "    data = data or {}\n",
        "\n",
        "    # Set default values if not provided\n",
        "    data['path'] = data['path'] if 'path' in data else base_config['path']\n",
        "    data['train'] = data['train'] if 'train' in data else base_config['train']\n",
        "    data['val'] = data['val'] if 'val' in data else base_config['val']\n",
        "    data['test'] = data['test'] if 'test' in data else base_config['test']\n",
        "    data['names'] = data['names'] if 'names' in data else base_config['names']\n",
        "\n",
        "    if use_default_config:\n",
        "\n",
        "        data = {**data, **default_config}\n",
        "\n",
        "    # Create configuration file\n",
        "    with open(filename, 'w') as file:\n",
        "        yaml.dump(data, file, default_flow_style=False)\n",
        "\n",
        "    return filename"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create configuration file\n",
        "We'll create a configuration file with the hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'data.yaml'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = {\n",
        "    'path': '/path/to/dataset',\n",
        "    'names': {\n",
        "        0: 'diente_leon',\n",
        "        1: 'kikuyo',\n",
        "        2: 'lengua_vaca',\n",
        "        3: 'otros',\n",
        "        4: 'papa',\n",
        "    },\n",
        "}\n",
        "\n",
        "create_configuration_file(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare model\n",
        "We'll download the rt-detr model and prepare it before training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics import RTDETR\n",
        "from wandb.integration.ultralytics import add_wandb_callback\n",
        "\n",
        "\n",
        "# Load a COCO-pretrained RT-DETR-l model\n",
        "model = RTDETR('rtdetr-l.pt')\n",
        "\n",
        "\n",
        "# Add W&B Callback for Ultralytics\n",
        "add_wandb_callback(model, enable_model_checkpointing=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select the mode that you prefer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbb2fd85915740ff9637395699f3437b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dropdown(description='Select one:', index=1, options=('train', 'tune'), value='tune')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from enum import Enum\n",
        "import ipywidgets as widgets\n",
        "\n",
        "Mode = Enum('Mode', ['tune', 'train'])\n",
        "\n",
        "dropdown = widgets.Dropdown(\n",
        "    options=[Mode.tune.name, Mode.train.name],\n",
        "    value=Mode.tune.name,\n",
        "    description='Select one:',\n",
        "    disabled=False,\n",
        ")\n",
        "dropdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mode  = dropdown.value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train/Tune the model\n",
        "Once you have selected the mode, you can train or tune the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if mode == Mode.train.name:\n",
        "    results = model.train(\n",
        "        project=project_name, name=name, data='data.yaml', device=[0, 1], batch=8, augment=True\n",
        "    )\n",
        "    results = model.val()\n",
        "else:\n",
        "    model.tune(\n",
        "    project=project_name, name=name, data='data.yaml',\n",
        "    device=[0, 1], batch=8, epochs=40, iterations=35, optimizer='SGD',imgsz=640\n",
        ")\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save the model\n",
        "We'll save the model in the output folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.export()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ia",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
